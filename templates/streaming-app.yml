AWSTemplateFormatVersion: "2010-09-09"
Description: "Stack for creating Kinesis Application"

Parameters:
  ProjectName:
    Type: String
    Description: Project Name
    MinLength: 4
    MaxLength: 20

  ApplicationName:
    Type: String
    Description: Application Name
    MinLength: 4
    MaxLength: 20

  DataStreamName:
    Type: String
    Description: Producer input stream name
    AllowedPattern: "^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$"
    ConstraintDescription: " Required. Must not start or end with a hyphen"
    MinLength: 4
    MaxLength: 20

  AnalyticsBucketArn:
    Type: String
    Description: Analytics Bucket ARN

Resources:
  DeliveryStreamRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - firehose.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: s3Access
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Sid: ""
                Effect: Allow
                Action:
                  - s3:AbortMultipartUpload
                  - s3:GetBucketLocation
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:ListBucketMultipartUploads
                  - s3:PutObject
                Resource:
                  - !Sub "${AnalyticsBucketArn}"
                  - !Sub "${AnalyticsBucketArn}/*"
              - Sid: ""
                Effect: Allow
                Action:
                  - logs:PutLogEvents
                Resource:
                  - !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:/aws/kinesisfirehose/*:log-stream:*"
  
  DeliveryStream:
    Type: AWS::KinesisFirehose::DeliveryStream
    Properties:
      DeliveryStreamType: DirectPut
      S3DestinationConfiguration:
        BucketARN: !Sub "${AnalyticsBucketArn}"
        BufferingHints:
          IntervalInSeconds: "60"
          SizeInMBs: "1"
        CompressionFormat: UNCOMPRESSED
        RoleARN: !GetAtt "DeliveryStreamRole.Arn"

  OutputStream:
    Type: AWS::Kinesis::Stream
    Properties:
      Name: !Sub "${AWS::StackName}-OutputStream"
      RetentionPeriodHours: 24
      ShardCount: 1

  KinesisAnalyticsRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - kinesisanalytics.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: kinesisaccess
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Sid: ReadInputStream
                Effect: Allow
                Action:
                  - kinesis:DescribeStream
                  - kinesis:GetShardIterator
                  - kinesis:GetRecords
                Resource:
                  - !Sub "arn:aws:kinesis:${AWS::Region}:${AWS::AccountId}:stream/${DataStreamName}"
              - Sid: ListStreams
                Effect: Allow
                Action:
                  - firehose:ListDeliveryStreams
                Resource: "*"
              - Sid: WriteOutputFirehose
                Effect: Allow
                Action:
                  - firehose:DescribeDeliveryStream
                  - firehose:PutRecord
                  - firehose:PutRecordBatch
                Resource:
                  - !GetAtt "DeliveryStream.Arn"

  KinesisApplication:
    Type: AWS::KinesisAnalytics::Application
    Properties:
      ApplicationName: !Ref ApplicationName
      ApplicationDescription: !Sub 'Kinesis Analytics for ${ProjectName}-${ApplicationName}'
      ApplicationCode: !Sub |
            CREATE STREAM "DESTINATION_SQL_STREAM"(
                MetricType VARCHAR(16),
                EventTimestamp BIGINT,
                MetricItem VARCHAR(1024),
                UnitValueInt BIGINT,
                UnitValueFloat DOUBLE);

            --Active Visitors
            CREATE OR REPLACE PUMP "VISTOR_COUNTER_PUMP" AS
            INSERT INTO "DESTINATION_SQL_STREAM" ( MetricType, EventTimestamp, UnitValueInt)
            SELECT STREAM 'visitor_count', UNIX_TIMESTAMP(weblogs.window_time), COUNT(weblogs.clientid) FROM (
                SELECT STREAM DISTINCT
                    monotonic (STEP (CHAR_TO_TIMESTAMP('dd/MMM/yyyy:HH:mm:ss z',"WASA_001"."datetime") by INTERVAL '60' SECOND)) AS window_time,
                    STEP ("WASA_001".ROWTIME BY INTERVAL '60' SECOND),
                    "WASA_001"."clientid" as clientid
                FROM "WASA_001") as weblogs
                GROUP BY
                window_time;

            --"Top" Page Views (group_rank?)
            CREATE OR REPLACE PUMP "PAGEVIEWS_PUMP" AS
            INSERT INTO "DESTINATION_SQL_STREAM" ( MetricType, EventTimestamp, MetricItem, UnitValueInt)
            SELECT 'top_pages', UNIX_TIMESTAMP(eventTimestamp), page, page_count FROM (
                SELECT stream
                    weblogs."page" as page,
                    count(*) as page_count,
                    STEP (CHAR_TO_TIMESTAMP('dd/MMM/yyyy:HH:mm:ss z',weblogs."datetime") by INTERVAL '10' SECOND) as eventTimestamp
                FROM "WASA_001" weblogs
                WHERE weblogs."page" is not NULL
                GROUP BY
                    STEP (weblogs.ROWTIME BY INTERVAL '10' SECOND),
                    STEP (CHAR_TO_TIMESTAMP('dd/MMM/yyyy:HH:mm:ss z',weblogs."datetime") by INTERVAL '10' SECOND),
                    weblogs."page"
                HAVING count(*) > 1
                ORDER BY STEP (weblogs.ROWTIME BY INTERVAL '10' SECOND), page_count desc
            );

            -- Events --
            CREATE STREAM "EVENT_STREAM"(
                MetricType VARCHAR(16),
                EventTimestamp BIGINT,
                MetricItem VARCHAR(1024),
                UnitValueInt BIGINT);
            CREATE OR REPLACE PUMP "SHARED_EVENT_PUMP" AS
            INSERT INTO "EVENT_STREAM" ( MetricType, EventTimestamp, MetricItem, UnitValueInt)
            SELECT 'event_count', UNIX_TIMESTAMP(eventTimestamp), event, event_count FROM (
                SELECT STREAM
                    STEP (CHAR_TO_TIMESTAMP('dd/MMM/yyyy:HH:mm:ss z',weblogs."datetime") by INTERVAL '10' SECOND) as eventTimestamp,
                    weblogs."event" event,
                    count(*) event_count
                FROM "WASA_001" weblogs
                WHERE weblogs."event" is not NULL
                GROUP BY
                    weblogs."event",
                    STEP (weblogs.ROWTIME BY INTERVAL '10' SECOND),
                    STEP (CHAR_TO_TIMESTAMP('dd/MMM/yyyy:HH:mm:ss z',weblogs."datetime") by INTERVAL '10' SECOND)
            );

            CREATE OR REPLACE PUMP "EVENT_PUMP" AS
            INSERT INTO "DESTINATION_SQL_STREAM" (MetricType, EventTimestamp, MetricItem, UnitValueInt)
            SELECT STREAM MetricType, EventTimestamp, MetricItem, UnitValueInt FROM "EVENT_STREAM";

            --Anomaly detection for event distribution
            CREATE STREAM "ANOMALY_TEMP_STREAM"(
                EventTimestampString VARCHAR(16),
                MetricItem VARCHAR(1024),
                MetricItemInt INTEGER,
                UnitValueInt BIGINT,
                AnomalyScore DOUBLE);
            CREATE OR REPLACE PUMP "INTERMEDIATE_ANOMALY_EVENT_PUMP" AS
            INSERT INTO "ANOMALY_TEMP_STREAM" ( EventTimestampString, MetricItem, MetricItemInt, UnitValueInt, AnomalyScore)
            SELECT STREAM *
            FROM TABLE (
                RANDOM_CUT_FOREST(
                    CURSOR(SELECT STREAM
                        CAST(EventTimestamp AS VARCHAR(16)),
                        MetricItem,
                        case MetricItem
                        WHEN 'click' THEN 1
                        WHEN 'pageview' THEN 2
                        WHEN 'conversion' THEN 3
                        WHEN 'exception' THEN 4
                        WHEN 'playvideo' THEN 5
                        WHEN 'login' THEN 6
                        WHEN 'logoff' THEN 7
                        ELSE 0
                        END,
                        UnitValueInt FROM "EVENT_STREAM"),
                        100,
                        256,
                        100000,
                        1)
                );

            CREATE OR REPLACE PUMP "ANOMALY_EVENT_PUMP" AS
            INSERT INTO "DESTINATION_SQL_STREAM" (MetricType, EventTimestamp, MetricItem, UnitValueFloat)
            SELECT 'event_anomaly', CAST(EventTimestampString AS BIGINT), MetricItem || ':' || CAST(UnitValueInt as VARCHAR(16)), AnomalyScore FROM (
                SELECT STREAM
                    EventTimestampString,
                    MetricItem,
                    UnitValueInt,
                    AnomalyScore
                FROM "ANOMALY_TEMP_STREAM"
                WHERE AnomalyScore > 2.0
            );

            --agents
            CREATE OR REPLACE PUMP "AGENT_PUMP" AS
            INSERT INTO "DESTINATION_SQL_STREAM" ( MetricType, EventTimestamp, MetricItem, UnitValueInt)
            SELECT 'agent_count', UNIX_TIMESTAMP(eventTimestamp), agent, agent_count FROM (
                SELECT STREAM
                    weblogs."agent" as agent,
                    count(*) as agent_count,
                    STEP (weblogs.ROWTIME BY INTERVAL '10' SECOND) as eventTimestamp
                FROM "WASA_001" weblogs
                WHERE weblogs."agent" NOT like 'ELB-HealthChecker%'
                GROUP BY
                    weblogs."agent",
                    STEP (weblogs.ROWTIME BY INTERVAL '10' SECOND)
            );

            --referrer (-r) list
            CREATE OR REPLACE PUMP "REFERRER_PUMP" AS
            INSERT INTO "DESTINATION_SQL_STREAM" ( MetricType, EventTimestamp, MetricItem, UnitValueInt)
            SELECT 'referral_count', UNIX_TIMESTAMP(eventTimestamp), referrer, referrer_count FROM (
                SELECT stream
                    weblogs."referrer" as referrer,
                    count(*) as referrer_count,
                    STEP (CHAR_TO_TIMESTAMP('dd/MMM/yyyy:HH:mm:ss z',weblogs."datetime") by INTERVAL '10' SECOND) as eventTimestamp
                FROM "WASA_001" weblogs
                GROUP BY
                    STEP (weblogs.ROWTIME BY INTERVAL '10' SECOND),
                    STEP (CHAR_TO_TIMESTAMP('dd/MMM/yyyy:HH:mm:ss z',weblogs."datetime") by INTERVAL '10' SECOND),
                    weblogs."referrer"
                ORDER BY STEP (weblogs.ROWTIME BY INTERVAL '10' SECOND), referrer_count desc
            );

            --Hourly Events
            CREATE OR REPLACE PUMP "HOURLY_EVENT_PUMP" AS
            INSERT INTO "DESTINATION_SQL_STREAM" ( MetricType, EventTimestamp, MetricItem, UnitValueInt)
            SELECT 'hourly_events', EventTimestamp, MetricItem, hourly_total FROM (
                SELECT STREAM
                    SUM(UnitValueInt) OVER hourly_window as hourly_total,
                    MetricItem,
                    EventTimestamp
                FROM "EVENT_STREAM"
                WINDOW hourly_window AS (
                    PARTITION BY MetricItem
                        RANGE INTERVAL '1' HOUR PRECEDING
                )
            );

      Inputs:
        - NamePrefix: RAW
          InputSchema:
            RecordColumns:
              - Name: transactionId
                SqlType: VARCHAR(20)
                Mapping: $.transactionId
              - Name: serviceName
                SqlType: VARCHAR(30)
                Mapping: $.serviceName
              - Name: msisdn
                SqlType: BIGINT
                Mapping: $.msisdn
              - Name: sourceSystem
                SqlType: VARCHAR(30)
                Mapping: $.sourceSystem
              - Name: callback
                SqlType: BOOLEAN
                Mapping: $.callback
              - Name: transactionType
                SqlType: VARCHAR(20)
                Mapping: $.transactionType
              - Name: productId
                SqlType: VARCHAR(20)
                Mapping: $.productId
              - Name: amount
                SqlType: DOUBLE
                Mapping: $.amount
              - Name: channel
                SqlType: VARCHAR(15)
                Mapping: $.channel
              - Name: checkoutRequestID
                SqlType: VARCHAR(50)
                Mapping: $.checkoutRequestID
              - Name: merchantRequestID
                SqlType: VARCHAR(50)
                Mapping: $.merchantRequestID
            RecordFormat:
              RecordFormatType: JSON
              MappingParameters:
                JSONMappingParameters:
                  RecordRowPath: $
          KinesisFirehoseInput:
            ResourceARN: !Sub 'arn:aws:firehose:${AWS::Region}:${AWS::AccountId}:deliverystream/${DeliveryStream}'
            RoleARN: !GetAtt 'KinesisAnalyticsRole.Arn'

  KinesisAnalyticsAppOutput:
    Type: AWS::KinesisAnalytics::ApplicationOutput
    Properties:
      ApplicationName: !Ref KinesisAnalyticsApp
      Output:
        DestinationSchema:
          RecordFormatType: JSON
        KinesisFirehoseOutput:
          ResourceARN: !GetAtt DeliveryStream.Arn
          RoleARN: !GetAtt KinesisAnalyticsRole.Arn
        Name: DESTINATION_SQL_STREAM

Outputs:
  Stream:
    Description: Streaming App
    Value: !Ref KinesisApplication
    Export:
      Name: !Sub "${AWS::StackName}:StreamApp"
